{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NN_classifier as nn\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "train_embeddings = pd.read_csv(\"data/opencv_em/embarray_train.txt\", sep=\" \", header=None)\n",
    "test_embeddings = pd.read_csv(\"data/cleaned/embarray_test.txt\", sep=\" \", header=None)\n",
    "train_labels = pd.read_csv(\"data/cleaned/paths_labels_train.txt\", sep=\" \", header=None, index_col = 0)\n",
    "test_labels = pd.read_csv(\"data/cleaned/paths_labels_test.txt\", sep=\" \", header= None, index_col = 0)\n",
    "train_labels.columns = [\"path\",\"label\"]\n",
    "test_labels.columns = [\"path\",\"label\"]\n",
    "train_labels.index.name = None\n",
    "test_labels.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shirley/Desktop/NEU/5500/code/NN_classifier.py:68: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shirley/Desktop/NEU/5500/code/NN_classifier.py:70: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shirley/Desktop/NEU/5500/code/NN_classifier.py:76: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shirley/Desktop/NEU/5500/code/NN_classifier.py:87: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shirley/Desktop/NEU/5500/code/NN_classifier.py:112: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shirley/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/shirley/Desktop/NEU/5500/code/NN_classifier.py:115: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shirley/Desktop/NEU/5500/code/NN_classifier.py:116: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Training Accuracy= 0.968000\n",
      "Training Accuracy= 0.979000\n",
      "Training Accuracy= 0.983000\n",
      "Training Accuracy= 0.983000\n",
      "Training Accuracy= 0.987000\n",
      "Test Accuracy= 0.983710\n",
      "WARNING:tensorflow:From /Users/shirley/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "final train accuracy : 0.9856863\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "final test accuracy : 0.98371\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "predicted labels:  (array([0.99982303, 0.9996006 , 0.99999964, ..., 0.99967206, 0.99832624,\n",
      "       0.99978167], dtype=float32), array([0, 0, 0, ..., 1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# when training the model, use mode 'Train'\n",
    "\n",
    "Xtrain, Ytrain,Xtest, Ytest = nn.get_normalized_data('Train',train_embeddings,train_labels,test_embeddings,test_labels)\n",
    "\n",
    "model = nn.TFNN(\"./tf.model\")\n",
    "model.fit(Xtrain, Ytrain, Xtest, Ytest)\n",
    "\n",
    "# test out the model via the predict function\n",
    "print(\"final train accuracy :\", model.predict_acc(Xtrain, Ytrain))\n",
    "print(\"final test accuracy :\", model.predict_acc(Xtest, Ytest))\n",
    "print('predicted labels: ', model.predict_label(Xtest))\n",
    "\n",
    "# save the model as json file\n",
    "# model.save(\"NN_model.json\")\n",
    "\n",
    "\n",
    "\n",
    "# # load the json file and score again\n",
    "# model = nn.TFNN.load(\"NN_model.json\")\n",
    "# print(\"final train accuracy (after reload):\", model.predict_acc(Xtrain, Ytrain))\n",
    "# print(\"final test accuracy (after reload):\", model.predict_acc(Xtest, Ytest))\n",
    "# print('predicted labels: ', model.predict_label(Xtest)[0])\n",
    "# print('probability: ', model.predict_label(Xtest)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "final test accuracy (after reload): 0.99581456\n"
     ]
    }
   ],
   "source": [
    "# when use the model to classify, use mode 'Classify' to get the normalized X inputs\n",
    "\n",
    "test = nn.get_normalized_data('Classifiy',test_embeddings)\n",
    "print(\"final test accuracy (after reload):\", model.predict_acc(test, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = train_embeddings.values\n",
    "y_train = train_labels[\"label\"].values\n",
    "X_test = test_embeddings.values\n",
    "y_test = test_labels[\"label\"].values\n",
    "\n",
    "logreg = LogisticRegression(random_state=0).fit(X, y_train)\n",
    "\n",
    "y_hat = logreg.predict(X_test)\n",
    "y_prob = logreg.predict_proba(X_test)\n",
    "acc = logreg.score(X_test, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99999857, 0.9999999 , 0.9999999 , ..., 0.99999976, 0.9489485 ,\n",
       "       0.9994843 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_label(Xtest)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mask wearing correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "train_embeddings = pd.read_csv(\"embarray_train.txt\", sep=\" \", header=None)\n",
    "test_embeddings = pd.read_csv(\"embarray_test.txt\", sep=\" \", header=None)\n",
    "\n",
    "train_labels = pd.read_csv('paths_labels_train.txt',sep=\" \", header=None, index_col = 0)\n",
    "test_labels = pd.read_csv('paths_labels_test.txt',sep=\" \", header=None, index_col = 0)\n",
    "\n",
    "train_labels.columns = [\"path\",\"label\"]\n",
    "test_labels.columns = [\"path\",\"label\"]\n",
    "train_labels.index.name = None\n",
    "test_labels.index.name = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy= 0.883000\n",
      "Training Accuracy= 0.883000\n",
      "Training Accuracy= 0.916000\n",
      "Training Accuracy= 0.913000\n",
      "Training Accuracy= 0.940000\n",
      "Training Accuracy= 0.922000\n",
      "Training Accuracy= 0.933000\n",
      "Training Accuracy= 0.943000\n",
      "Training Accuracy= 0.949000\n",
      "Training Accuracy= 0.952000\n",
      "Test Accuracy= 0.880923\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "final train accuracy : 0.94720024\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "final test accuracy : 0.8809232\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "predicted labels:  [0.787562   0.49727938 0.8020821  ... 0.9991744  0.997051   0.9975418 ]\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain,Xtest, Ytest = nn.get_normalized_data(train_embeddings,train_labels,test_embeddings,test_labels)\n",
    "\n",
    "model_d = nn.TFNN(\"./tf.model\")\n",
    "model_d.fit(Xtrain, Ytrain, Xtest, Ytest)\n",
    "\n",
    "# test out the model via the predict function\n",
    "print(\"final train accuracy :\", model_d.predict_acc(Xtrain, Ytrain))\n",
    "print(\"final test accuracy :\", model_d.predict_acc(Xtest, Ytest))\n",
    "print('predicted labels: ', model_d.predict_label(Xtest)[0])\n",
    "\n",
    "# #  save the model as json file\n",
    "# model.save(\"NN_model.json\")\n",
    "\n",
    "\n",
    "\n",
    "# # load the json file and score again\n",
    "# model = nn.TFNN.load(\"NN_model.json\")\n",
    "# print(\"final train accuracy (after reload):\", model.predict_acc(Xtrain, Ytrain))\n",
    "# print(\"final test accuracy (after reload):\", model.predict_acc(Xtest, Ytest))\n",
    "# print('predicted labels: ', model.predict_label(Xtest)[0])\n",
    "# print('probability: ', model.predict_label(Xtest)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirley/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/shirley/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8354607448854695"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = train_embeddings.values\n",
    "y_train = train_labels['label'].values\n",
    "X_test = test_embeddings.values\n",
    "y_test = test_labels['label'].values\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, class_weight = 'balanced').fit(X, y_train)\n",
    "\n",
    "y_hat = logreg.predict(X_test)\n",
    "y_prob = logreg.predict_proba(X_test)\n",
    "acc = logreg.score(X_test, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875309529515137"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "train_embeddings = pd.read_csv(\"embarray_train_g.txt\", sep=\" \", header=None)\n",
    "test_embeddings = pd.read_csv(\"embarray_test_g.txt\", sep=\" \", header=None)\n",
    "\n",
    "train_labels = pd.read_csv('paths_labels_train_g.txt',sep=\" \", header=None, index_col = 0)\n",
    "test_labels = pd.read_csv('paths_labels_test_g.txt',sep=\" \", header=None, index_col = 0)\n",
    "\n",
    "train_labels.columns = [\"path\",\"label\"]\n",
    "test_labels.columns = [\"path\",\"label\"]\n",
    "train_labels.index.name = None\n",
    "test_labels.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy= 0.959000\n",
      "Training Accuracy= 0.962000\n",
      "Training Accuracy= 0.968000\n",
      "Training Accuracy= 0.970000\n",
      "Training Accuracy= 0.971000\n",
      "Training Accuracy= 0.968000\n",
      "Training Accuracy= 0.975000\n",
      "Training Accuracy= 0.983000\n",
      "Training Accuracy= 0.971000\n",
      "Training Accuracy= 0.971000\n",
      "Test Accuracy= 0.959958\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "final train accuracy : 0.9807093\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "final test accuracy : 0.959958\n",
      "INFO:tensorflow:Restoring parameters from ./tf.model\n",
      "predicted labels:  [0.9748447 0.9435926 0.7858358 ... 0.9999232 0.9960199 0.9971776]\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain,Xtest, Ytest = nn.get_normalized_data(train_embeddings,train_labels,test_embeddings,test_labels)\n",
    "\n",
    "model_g = nn.TFNN(\"./tf.model\")\n",
    "model_g.fit(Xtrain, Ytrain, Xtest, Ytest)\n",
    "\n",
    "# test out the model via the predict function\n",
    "print(\"final train accuracy :\", model_g.predict_acc(Xtrain, Ytrain))\n",
    "print(\"final test accuracy :\", model_g.predict_acc(Xtest, Ytest))\n",
    "print('predicted labels: ', model_g.predict_label(Xtest)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try the multioutput classifier in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = pd.read_csv(\"embarray_train.txt\", sep=\" \", header=None)\n",
    "test_embeddings = pd.read_csv(\"embarray_test.txt\", sep=\" \", header=None)\n",
    "\n",
    "train_labels = pd.read_csv('paths_labels_train.txt',sep=\" \", header=None, index_col = 0)\n",
    "test_labels = pd.read_csv('paths_labels_test.txt',sep=\" \", header=None, index_col = 0)\n",
    "\n",
    "train_labels.columns = [\"path\",\"degree\"]\n",
    "test_labels.columns = [\"path\",\"degree\"]\n",
    "train_labels.index.name = None\n",
    "test_labels.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_g = pd.read_csv('paths_labels_train_g.txt',sep=\" \", header=None, index_col = 0)\n",
    "test_labels_g = pd.read_csv('paths_labels_test_g.txt',sep=\" \", header=None, index_col = 0)\n",
    "\n",
    "train_labels_g.columns = [\"path\",\"glass\"]\n",
    "test_labels_g.columns = [\"path\",\"glass\"]\n",
    "train_labels_g.index.name = None\n",
    "test_labels_g.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.merge(train_labels_g, on = 'path')\n",
    "test_labels = test_labels.merge(test_labels_g, on = 'path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_embeddings.values\n",
    "y_train = train_labels[['degree','glass']].values\n",
    "X_test = test_embeddings.values\n",
    "y_test = test_labels[['degree','glass']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirley/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/shirley/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(C=1.0,\n",
       "                                                   class_weight='balanced',\n",
       "                                                   dual=False,\n",
       "                                                   fit_intercept=True,\n",
       "                                                   intercept_scaling=1,\n",
       "                                                   l1_ratio=None, max_iter=100,\n",
       "                                                   multi_class='auto',\n",
       "                                                   n_jobs=None, penalty='l2',\n",
       "                                                   random_state=0,\n",
       "                                                   solver='warn', tol=0.0001,\n",
       "                                                   verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                      n_jobs=None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(random_state=0, class_weight = 'balanced',multi_class = 'auto')\n",
    "model = MultiOutputClassifier(estimator=logistic)\n",
    "model.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7412134988634377\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc degree: 0.838084, glass: 0.959259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "yhat = model.predict(X_test)\n",
    "auc_y1 = accuracy_score(y_test[:,0], yhat[:,0])\n",
    "auc_y2 = accuracy_score(y_test[:,1], yhat[:,1])\n",
    "print(\"acc degree: %.4f, glass: %.4f\" % (auc_y1, auc_y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=None,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators='warn',\n",
       "                                                       n_jobs=None,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_state=1,\n",
       "                                                       verbose=0,\n",
       "                                                       warm_start=False),\n",
       "                      n_jobs=-1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "model_2 = MultiOutputClassifier(estimator=forest,n_jobs=-1)\n",
    "model_2.fit(X, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8045112781954887\n"
     ]
    }
   ],
   "source": [
    "print(model_2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc degree: 0.838084, glass: 0.959259\n"
     ]
    }
   ],
   "source": [
    "yhat_2 = model_2.predict(X_test)\n",
    "\n",
    "auc_y1 = accuracy_score(y_test[:,0], yhat_2[:,0])\n",
    "auc_y2 = accuracy_score(y_test[:,1], yhat_2[:,1])\n",
    "print(\"acc degree: %.6f, glass: %.6f\" % (auc_y1, auc_y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                         criterion='gini',\n",
       "                                                                                         max_depth=1,\n",
       "                                                                                         max_features=None,\n",
       "                                                                                         max_leaf_nodes=None,\n",
       "                                                                                         min_impurity_decrease=0.0,\n",
       "                                                                                         min_impurity_split=None,\n",
       "                                                                                         min_samples_leaf=1,\n",
       "                                                                                         min_samples_split=2,\n",
       "                                                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                                                         presort=False,\n",
       "                                                                                         random_state=None,\n",
       "                                                                                         splitter='best'),\n",
       "                                                   learning_rate=1.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   random_state=None),\n",
       "                      n_jobs=-1)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    ")\n",
    "model_3 = MultiOutputClassifier(estimator=AdaBoost,n_jobs=-1)\n",
    "model_3.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8027627207553768\n"
     ]
    }
   ],
   "source": [
    "print(model_3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc degree: 0.840532, glass: 0.952789\n"
     ]
    }
   ],
   "source": [
    "yhat_3 = model_3.predict(X_test)\n",
    "\n",
    "auc_y1 = accuracy_score(y_test[:,0], yhat_3[:,0])\n",
    "auc_y2 = accuracy_score(y_test[:,1], yhat_3[:,1])\n",
    "print(\"acc degree: %.6f, glass: %.6f\" % (auc_y1, auc_y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.18      0.24       268\n",
      "           1       0.48      0.24      0.32       729\n",
      "           2       0.88      0.97      0.92      4722\n",
      "\n",
      "    accuracy                           0.84      5719\n",
      "   macro avg       0.58      0.46      0.50      5719\n",
      "weighted avg       0.80      0.84      0.81      5719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.57      0.50       235\n",
      "           1       0.98      0.97      0.98      5484\n",
      "\n",
      "    accuracy                           0.95      5719\n",
      "   macro avg       0.71      0.77      0.74      5719\n",
      "weighted avg       0.96      0.95      0.96      5719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr_y1 = classification_report(y_test[:,0],yhat_3[:,0])\n",
    "cr_y2 = classification_report(y_test[:,1],yhat_3[:,1])\n",
    "\n",
    "print(cr_y1)\n",
    "print(cr_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to deal with the imbalanced data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### refer to image processing local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wearing correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings for occlusion\n",
    "\n",
    "train_embeddings = pd.read_csv(\"data/MAFA/wearing_correct/embarray_train.txt\", sep=\" \", header=None)\n",
    "test_embeddings = pd.read_csv(\"data/MAFA/wearing_correct/embarray_test.txt\", sep=\" \", header=None)\n",
    "train_labels = pd.read_csv(\"data/MAFA/wearing_correct/paths_labels_train.txt\", sep=\" \", header=None, index_col = 0)\n",
    "test_labels = pd.read_csv(\"data/MAFA/wearing_correct/paths_labels_test.txt\", sep=\" \", header= None, index_col = 0)\n",
    "train_labels.columns = [\"path\",\"label\"]\n",
    "test_labels.columns = [\"path\",\"label\"]\n",
    "train_labels.index.name = None\n",
    "test_labels.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    33640\n",
       "0    21674\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## not correct is labeled with 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirley/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8220342047221318\n",
      "test accuracy:  0.7635950340968701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X = train_embeddings.values\n",
    "y_train = train_labels['label'].values\n",
    "X_test = test_embeddings.values\n",
    "y_test = test_labels['label'].values\n",
    "scaler.fit(X)\n",
    "\n",
    "trainX = scaler.transform(X)\n",
    "testX = scaler.transform(X_test)\n",
    "# pickle.dump(scaler, open('code/log_sc.pkl','wb'))\n",
    "\n",
    "logreg = LogisticRegression(random_state=0,max_iter=500).fit(trainX, y_train)\n",
    "\n",
    "y_hat = logreg.predict(testX)\n",
    "y_prob = logreg.predict_proba(testX)\n",
    "acc = logreg.score(testX, y_test)\n",
    "\n",
    "print('training accuracy: ',logreg.score(trainX, y_train))\n",
    "print('test accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8032505333188704\n",
      "test accuracy:  0.7254764819024305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "AdaBoost = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    ")\n",
    "AdaBoost.fit(trainX, y_train)\n",
    "y_hat = AdaBoost.predict(testX)\n",
    "y_prob = AdaBoost.predict_proba(testX)\n",
    "acc = AdaBoost.score(testX, y_test)\n",
    "print('training accuracy: ',AdaBoost.score(trainX, y_train))\n",
    "print('test accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  1.0\n",
      "test accuracy:  0.813953488372093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1,n_estimators = 100)\n",
    "forest.fit(trainX, y_train)\n",
    "y_hat = forest.predict(testX)\n",
    "y_prob = forest.predict_proba(testX)\n",
    "acc = forest.score(testX, y_test)\n",
    "print('training accuracy: ',forest.score(trainX, y_train))\n",
    "print('test accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      4722\n",
      "           1       0.53      0.82      0.64       997\n",
      "\n",
      "    accuracy                           0.84      5719\n",
      "   macro avg       0.74      0.83      0.77      5719\n",
      "weighted avg       0.88      0.84      0.85      5719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr_y1 = classification_report(y_test,y_hat)\n",
    "print(cr_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8594026828650975\n",
      "test accuracy:  0.8415806959258612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8594026828650975"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = train_embeddings.values\n",
    "y_train = train_labels['label'].values\n",
    "X_test = test_embeddings.values\n",
    "y_test = test_labels['label'].values\n",
    "scaler.fit(X)\n",
    "\n",
    "trainX = scaler.transform(X)\n",
    "testX = scaler.transform(X_test)\n",
    "pickle.dump(scaler, open('code/correct_sc.pkl','wb'))\n",
    "\n",
    "nn_c = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "nn_c.fit(trainX, y_train)\n",
    "y_hat = nn_c.predict(testX)\n",
    "y_prob = nn_c.predict_proba(testX)\n",
    "acc = nn_c.score(testX, y_test)\n",
    "print('training accuracy: ',nn_c.score(trainX, y_train))\n",
    "print('test accuracy: ', acc)\n",
    "\n",
    "pickle.dump(nn_c, open(\"code/correctness_nn.pkl\", 'wb'))\n",
    "\n",
    "nn_c_reload = pickle.load(open(\"code/correctness_nn.pkl\",'rb'))\n",
    "nn_c_reload.score(trainX, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# human body occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings for human body\n",
    "\n",
    "train_embeddings_hb = pd.read_csv(\"data/MAFA/wearing_hb/embarray_train.txt\", sep=\" \", header=None)\n",
    "test_embeddings_hb = pd.read_csv(\"data/MAFA/wearing_hb/embarray_test.txt\", sep=\" \", header=None)\n",
    "train_labels_hb = pd.read_csv(\"data/MAFA/wearing_hb/paths_labels_train.txt\", sep=\" \", header=None, index_col = 0)\n",
    "test_labels_hb = pd.read_csv(\"data/MAFA/wearing_hb/paths_labels_test.txt\", sep=\" \", header= None, index_col = 0)\n",
    "train_labels_hb.columns = [\"path\",\"label\"]\n",
    "test_labels_hb.columns = [\"path\",\"label\"]\n",
    "train_labels_hb.index.name = None\n",
    "test_labels_hb.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23172\n",
       "0    18660\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_hb['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## human body is labeled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.1656148403136355\n",
      "test accuracy:  0.06557377049180328\n"
     ]
    }
   ],
   "source": [
    "X_hb = train_embeddings_hb.values\n",
    "y_train_hb = train_labels_hb['label'].values\n",
    "X_test_hb = test_embeddings_hb.values\n",
    "y_test_hb = test_labels_hb['label'].values\n",
    "scaler.fit(X_hb)\n",
    "\n",
    "trainX_hb = scaler.transform(X_hb)\n",
    "testX_hb = scaler.transform(X_test_hb)\n",
    "# pickle.dump(scaler, open('code/correct_sc.pkl','wb'))\n",
    "\n",
    "forest_hb = RandomForestClassifier(random_state=1,n_estimators = 100)\n",
    "forest_hb.fit(trainX_hb, y_train_hb)\n",
    "y_hat_hb = forest.predict(testX_hb)\n",
    "y_prob_hb = forest.predict_proba(testX_hb)\n",
    "acc = forest.score(testX_hb, y_test_hb)\n",
    "print('training accuracy: ',forest.score(trainX_hb, y_train_hb))\n",
    "print('test accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8068942436412316\n",
      "test accuracy:  0.7844028676342018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8068942436412316"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_hb = train_embeddings_hb.values\n",
    "y_train_hb = train_labels_hb['label'].values\n",
    "X_test_hb = test_embeddings_hb.values\n",
    "y_test_hb = test_labels_hb['label'].values\n",
    "scaler.fit(X_hb)\n",
    "\n",
    "trainX_hb = scaler.transform(X_hb)\n",
    "testX_hb = scaler.transform(X_test_hb)\n",
    "pickle.dump(scaler, open('code/hb_sc.pkl','wb'))\n",
    "\n",
    "nn_hb = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(10, 3), random_state=1)\n",
    "\n",
    "nn_hb.fit(trainX_hb, y_train_hb)\n",
    "y_hat_hb = nn_hb.predict(testX_hb)\n",
    "y_prob_hb = nn_hb.predict_proba(testX_hb)\n",
    "acc = nn_hb.score(testX_hb, y_test_hb)\n",
    "print('training accuracy: ',nn_hb.score(trainX_hb, y_train_hb))\n",
    "print('test accuracy: ', acc)\n",
    "\n",
    "pickle.dump(nn_hb, open(\"code/hb_nn.pkl\", 'wb'))\n",
    "\n",
    "nn_hb_reload = pickle.load(open(\"code/hb_nn.pkl\",'rb'))\n",
    "nn_hb_reload.score(trainX_hb, y_train_hb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.64      0.39       621\n",
      "           1       0.95      0.80      0.87      5098\n",
      "\n",
      "    accuracy                           0.78      5719\n",
      "   macro avg       0.61      0.72      0.63      5719\n",
      "weighted avg       0.88      0.78      0.82      5719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr_y2 = classification_report(y_test_hb,y_hat_hb)\n",
    "print(cr_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 396,  225],\n",
       "       [1008, 4090]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_hb, y_hat_hb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7545025354082882"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_hb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8914145829690505"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_hb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings for human body\n",
    "\n",
    "train_embeddings_3 = pd.read_csv(\"data/our_photos/embeddings/embarray_train.txt\", sep=\" \", header=None)\n",
    "test_embeddings_3 = pd.read_csv(\"data/our_photos/embeddings/embarray_test.txt\", sep=\" \", header=None)\n",
    "train_labels_3 = pd.read_csv(\"data/our_photos/embeddings/paths_labels_train.txt\", sep=\" \", header=None, index_col = 0)\n",
    "test_labels_3 = pd.read_csv(\"data/our_photos/embeddings/paths_labels_test.txt\", sep=\" \", header= None, index_col = 0)\n",
    "train_labels_3.columns = [\"path\",\"label\"]\n",
    "test_labels_3.columns = [\"path\",\"label\"]\n",
    "train_labels_3.index.name = None\n",
    "test_labels_3.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    68\n",
       "0    62\n",
       "2    61\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_3['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  1.0\n",
      "test accuracy:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirley/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/shirley/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_3 = train_embeddings_3.values\n",
    "y_train_3 = train_labels_3['label'].values\n",
    "X_test_3 = test_embeddings_3.values\n",
    "y_test_3 = test_labels_3['label'].values\n",
    "scaler.fit(X_3)\n",
    "\n",
    "trainX_3 = scaler.transform(X_3)\n",
    "testX_3 = scaler.transform(X_test_3)\n",
    "pickle.dump(scaler, open('code/face3_sc.pkl','wb'))\n",
    "\n",
    "logreg = LogisticRegression(random_state=0,max_iter=500).fit(trainX_3, y_train_3)\n",
    "\n",
    "y_hat_3 = logreg.predict(testX_3)\n",
    "y_prob_3 = logreg.predict_proba(testX_3)\n",
    "acc = logreg.score(testX_3, y_test_3)\n",
    "\n",
    "print('training accuracy: ',logreg.score(trainX_3, y_train_3))\n",
    "print('test accuracy: ', acc)\n",
    "\n",
    "pickle.dump(logreg, open(\"code/face3_logreg.pkl\", 'wb'))\n",
    "\n",
    "log_reload = pickle.load(open(\"code/face3_logreg.pkl\",'rb'))\n",
    "log_reload.score(trainX_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr_y3 = classification_report(y_test_3,y_hat_3)\n",
    "print(cr_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0, 10,  0],\n",
       "       [ 0,  0, 10]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_3, y_hat_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
