{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "how-to-use-facenet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOj3u9GuXvw0Kxd5wH4QsZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tonyz4516/detector-for-masked-faces/blob/master/how_to_use_facenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAB3Fdo6VGfs"
      },
      "source": [
        "For reference：\n",
        "\n",
        "https://medium.com/@athul929/building-a-facial-recognition-system-with-facenet-b9c249c2388a\n",
        "\n",
        "https://pypi.org/project/facenet-sandberg/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HrPp9OsPg_Q"
      },
      "source": [
        "First clone two repositories:\n",
        "1. davidsandberg's facenet model\n",
        "2. our own git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddYTFt7POPSv",
        "outputId": "2171457d-3a59-46c8-cc47-da78bbe2569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "! git clone https://github.com/davidsandberg/facenet.git\n",
        "! git clone https://github.com/Tonyz4516/detector-for-masked-faces.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'facenet'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3149 (delta 0), reused 0 (delta 0), pack-reused 3146\u001b[K\n",
            "Receiving objects: 100% (3149/3149), 2.94 MiB | 21.48 MiB/s, done.\n",
            "Resolving deltas: 100% (2229/2229), done.\n",
            "Cloning into 'detector-for-masked-faces'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 73 (delta 0), reused 0 (delta 0), pack-reused 70\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA7vr07yPn5L"
      },
      "source": [
        "Then replace two files in david's git with our own mofification:\n",
        "1. classifier.py\n",
        "2. facenet.py\n",
        "\n",
        "The modifications include: \n",
        "1. tensorflow version from 1.7 to 2.3; \n",
        "2. small code to save some needed files, such as embeddings, predicted results, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjL32BC6OegL"
      },
      "source": [
        "! rm ./facenet/src/classifier.py\n",
        "! cp ./detector-for-masked-faces/classifier.py ./facenet/src/classifier.py"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "git_xssqPS4c"
      },
      "source": [
        "! rm ./facenet/src/facenet.py\n",
        "! cp ./detector-for-masked-faces/facenet.py ./facenet/src/facenet.py"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYwtGduISJkA"
      },
      "source": [
        "! cp ./detector-for-masked-faces/pre-trained_facenet_model/20180402-114759.pb ./facenet/src/models/20180402-114759.pb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z_CVDr7Ti04"
      },
      "source": [
        "data directory format: \\\n",
        "data/    \n",
        "&emsp;train/    \n",
        "&emsp;&emsp;label1(face)/ \\\n",
        "&emsp;&emsp;&emsp;image1.jpg \\\n",
        "&emsp;&emsp;&emsp;image2.jpg \\\n",
        "&emsp;&emsp;&emsp;…… \\\n",
        "&emsp;test/    \n",
        "&emsp;&emsp;label2(mask)/ \\\n",
        "&emsp;&emsp;&emsp;image1.jpg \\\n",
        "&emsp;&emsp;&emsp;image2.jpg \\\n",
        "&emsp;&emsp;&emsp;……\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NpO11tAQLRQ"
      },
      "source": [
        "Resize all images to 160x160 and set up data format, then use the following command to run the code.\n",
        "\n",
        "Note: if you only want the embeddings and don't want to use the SVM model in classifier.py, you need to comment out line 97 to line 131 in classifier.py.\n",
        "\n",
        "Train:\n",
        "\n",
        "format:\n",
        "run PATH_CLASSIFER --test_data_dir PATH_TEST_DATA TRAIN PATH_TRAIN_DATA PATH_PRE-TRAINED_FACENET_MODEL NAME_OF_GENERATED_MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euisY4FZPW0m"
      },
      "source": [
        "! run \"./facenet/src/classifier.py\" --test_data_dir \"drive/My Drive/5500_Project/5500_data/data/test\" TRAIN \"drive/My Drive/5500_Project/5500_data/data/train\" \"./facenet/src/models/20180402-114759.pb\" \"model.pkl\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsft6zpFSr3e"
      },
      "source": [
        "After training, there will be a model file generated as \"model.pkl\", then you can use it to run the test command as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgHouRC6Qn8B"
      },
      "source": [
        "Test:\n",
        "\n",
        "format:\n",
        "run PATH_CLASSIFER --test_data_dir PATH_TEST_DATA CLASSIFY PATH_TEST_DATA PATH_PRE-TRAINED_FACENET_MODEL NAME_OF_GENERATED_MODEL_IN_TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sgKekSOQpeK"
      },
      "source": [
        "! run \"./facenet/src/classifier.py\" --test_data_dir \"drive/My Drive/5500_Project/5500_data/data/test\" CLASSIFY \"drive/My Drive/5500_Project/5500_data/data/test\" \"./facenet/src/models/20180402-114759.pb\" \"model.pkl\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}