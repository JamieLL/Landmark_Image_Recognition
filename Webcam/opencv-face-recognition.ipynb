{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import embedding\n",
    "import resize\n",
    "import facenet\n",
    "import tensorflow as tf\n",
    "# construct the argument parser and parse the arguments\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-d\", \"--detector\", required=True,\n",
    "#     help=\"path to OpenCV's deep learning face detector\")\n",
    "# ap.add_argument(\"-m\", \"--embedding-model\", required=True,\n",
    "#     help=\"path to OpenCV's deep learning face embedding model\")\n",
    "# ap.add_argument(\"-r\", \"--recognizer\", required=True,\n",
    "#     help=\"path to model trained to recognize faces\")\n",
    "# ap.add_argument(\"-l\", \"--le\", required=True,\n",
    "#     help=\"path to label encoder\")\n",
    "# ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
    "#     help=\"minimum probability to filter weak detections\")\n",
    "# args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"detector\"] = \"./model/face_detection_model\"\n",
    "args[\"embedding_model\"] = \"./model/20180402-114759.pb\"\n",
    "args[\"recognizer\"] = \"./model/mask_detector/face_detector_log.pkl\"\n",
    "args[\"recog_sc\"] = \"./model/mask_detector/log_sc.pkl\"\n",
    "args[\"le\"] = \"./model/mask_detector/le.pickle\"\n",
    "args[\"confidence\"] = 0.5\n",
    "\n",
    "args[\"wearc_model\"] = \"./model/wearing_correctness/correctness_nn.pkl\"\n",
    "args[\"wearc_sc\"] = \"./model/wearing_correctness/correct_sc.pkl\"\n",
    "\n",
    "args[\"face3_model\"] = \"./model/face_recognition/face3_logreg.pkl\"\n",
    "args[\"face3_sc\"] = \"./model/face_recognition/face3_sc.pkl\"\n",
    "args[\"face3_le\"] = \"./model/face_recognition/face3_le.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector...\n",
      "[INFO] loading face recognizer...\n"
     ]
    }
   ],
   "source": [
    "# load our serialized face detector from disk\n",
    "print(\"[INFO] loading face detector...\")\n",
    "protoPath = os.path.sep.join([args[\"detector\"], \"deploy.prototxt\"])\n",
    "modelPath = os.path.sep.join([args[\"detector\"],\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "# load our serialized face embedding model from disk\n",
    "print(\"[INFO] loading face recognizer...\")\n",
    "recog_sc = pickle.load(open(args[\"recog_sc\"],'rb'))\n",
    "recognizer = pickle.load(open(args[\"recognizer\"],'rb'))\n",
    "le = pickle.loads(open(args[\"le\"], \"rb\").read())\n",
    "\n",
    "wearc_model = pickle.load(open(args[\"wearc_model\"],'rb'))\n",
    "wearc_sc = pickle.load(open(args[\"wearc_sc\"],'rb'))\n",
    "\n",
    "face3_model = pickle.load(open(args[\"face3_model\"],'rb'))\n",
    "face3_sc = pickle.load(open(args[\"face3_sc\"],'rb'))\n",
    "face3_le = pickle.loads(open(args[\"face3_le\"], \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature extraction model\n",
      "Model filename: ./model/20180402-114759.pb\n",
      "[INFO] starting video stream...\n",
      "[INFO] elasped time: 1750.27\n",
      "[INFO] approx. FPS: 9.14\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        np.random.seed(seed=666)\n",
    "        # Load the model\n",
    "        print('Loading feature extraction model')\n",
    "        facenet.load_model(args[\"embedding_model\"])\n",
    "\n",
    "        \n",
    "        # initialize the video stream, then allow the camera sensor to warm up\n",
    "        print(\"[INFO] starting video stream...\")\n",
    "        vs = VideoStream(src=0).start()\n",
    "#         time.sleep(2.0)\n",
    "\n",
    "        # start the FPS throughput estimator\n",
    "        fps = FPS().start()\n",
    "        \n",
    "        \n",
    "        # loop over frames from the video file stream\n",
    "        while True:\n",
    "            # grab the frame from the threaded video stream\n",
    "            frame = vs.read()\n",
    "\n",
    "            # resize the frame to have a width of 600 pixels (while\n",
    "            # maintaining the aspect ratio), and then grab the image\n",
    "            # dimensions\n",
    "            frame = imutils.resize(frame, width=600)\n",
    "            (h, w) = frame.shape[:2]\n",
    "\n",
    "            # construct a blob from the image\n",
    "            imageBlob = cv2.dnn.blobFromImage(\n",
    "                cv2.resize(frame, (300, 300)), 1.0, (300, 300),\n",
    "                (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "            # apply OpenCV's deep learning-based face detector to localize\n",
    "            # faces in the input image\n",
    "            detector.setInput(imageBlob)\n",
    "            detections = detector.forward()\n",
    "\n",
    "            # loop over the detections\n",
    "            for i in range(0, detections.shape[2]):\n",
    "                # extract the confidence (i.e., probability) associated with\n",
    "                # the prediction\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                # filter out weak detections\n",
    "                if confidence > args[\"confidence\"]:\n",
    "                    # compute the (x, y)-coordinates of the bounding box for\n",
    "                    # the face\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                    # extract the face ROI\n",
    "                    face = frame[startY:endY, startX:endX]\n",
    "                    (fH, fW) = face.shape[:2]\n",
    "\n",
    "                    # ensure the face width and height are sufficiently large\n",
    "                    if fW < 20 or fH < 20:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    img = resize.resize_addframe(face, 160, 160)\n",
    "            \n",
    "                    \n",
    "                    # Get input and output tensors\n",
    "                    images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "                    embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "                    phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "                    embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "                    # Run forward pass to calculate embeddings\n",
    "                    emb_array = np.zeros((1, embedding_size))\n",
    "                    images = facenet.load_data(img, False, False, 160)\n",
    "                    feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n",
    "                    emb_array = sess.run(embeddings, feed_dict=feed_dict)\n",
    "                    vec = emb_array\n",
    "\n",
    "                    # perform classification to recognize the face\n",
    "                    vec_nor = recog_sc.transform(vec)\n",
    "                    pred_label = recognizer.predict(vec_nor)\n",
    "                    proba = recognizer.predict_proba(vec_nor)[0][int(pred_label)]\n",
    "#                     print(pred_label, proba)\n",
    "                    name = le.classes_[int(pred_label)]\n",
    "    \n",
    "                    if name == \"mask\":\n",
    "                        vec_nor = wearc_sc.transform(vec)\n",
    "                        wearc_label = wearc_model.predict(vec_nor)\n",
    "                        wearc_proba = wearc_model.predict_proba(vec_nor)[0][int(wearc_label)]\n",
    "                        if int(wearc_label) == 0:\n",
    "                            tip = \"wearing correctly\"\n",
    "                        elif int(wearc_label) == 1:\n",
    "                            tip = \"please wear your mask correctly\"\n",
    "                    elif name == \"face\":\n",
    "                        vec_nor = face3_sc.transform(vec)\n",
    "                        face3_label = face3_model.predict(vec_nor)\n",
    "                        face3_proba = face3_model.predict_proba(vec_nor)[0][int(face3_label)]\n",
    "                        person = face3_le.classes_[int(face3_label)]\n",
    "                        tip = person + \": please wear your mask\"\n",
    "                        \n",
    "\n",
    "                    # draw the bounding box of the face along with the\n",
    "                    # associated probability\n",
    "                    text = \"{}: {:.2f}%\".format(tip, float(proba) * 100)\n",
    "                    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                    if tip == \"wearing correctly\":\n",
    "                        cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                        (0, 255, 0), 2)\n",
    "                        cv2.putText(frame, text, (startX, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "                    elif tip == \"please wear your mask correctly\":\n",
    "                        cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                            (0, 255, 255), 2)\n",
    "                        cv2.putText(frame, text, (startX, y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,255,255), 2)\n",
    "                    else:\n",
    "                        cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                            (0, 0, 255), 2)\n",
    "                        cv2.putText(frame, text, (startX, y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "\n",
    "            # update the FPS counter\n",
    "            fps.update()\n",
    "\n",
    "            # show the output frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        # stop the timer and display FPS information\n",
    "        fps.stop()\n",
    "        print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "        print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "        # do a bit of cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        vs.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
